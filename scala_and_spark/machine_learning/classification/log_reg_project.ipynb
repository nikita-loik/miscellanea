{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.0.22:4040\n",
       "SparkContext available as 'sc' (version = 3.0.0, master = local[*], app id = local-1601729290158)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Daily Time Spent on Site: double (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Area Income: double (nullable = true)\n",
      " |-- Daily Internet Usage: double (nullable = true)\n",
      " |-- Ad Topic Line: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Male: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Timestamp: string (nullable = true)\n",
      " |-- Clicked on Ad: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.classification.LogisticRegression\n",
       "import org.apache.spark.sql.SparkSession\n",
       "import org.apache.spark.ml.feature.{VectorAssembler, StringIndexer, VectorIndexer, OneHotEncoder}\n",
       "import org.apache.spark.ml.linalg.Vectors\n",
       "import org.apache.spark.ml.Pipeline\n",
       "import org.apache.spark.mllib.evaluation.MulticlassMetrics\n",
       "import org.apache.log4j._\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@3eba8e61\n",
       "data: org.apache.spark.sql.DataFrame = [Daily Time Spent on Site: double, Age: int ... 8 more fields]\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 1. GET THE DATA\n",
    "\n",
    "// Import SparkSession and LogisticRegression.\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "// Import VectorAssembler and Vectors\n",
    "import org.apache.spark.ml.feature.{VectorAssembler,StringIndexer,VectorIndexer,OneHotEncoder}\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "\n",
    "// Import Pipeline\n",
    "import org.apache.spark.ml.Pipeline\n",
    "\n",
    "// For Metrics and Evaluation import MulticlassMetrics\n",
    "import org.apache.spark.mllib.evaluation.MulticlassMetrics\n",
    "\n",
    "// Set error reporting.\n",
    "import org.apache.log4j._\n",
    "Logger.getLogger(\"org\").setLevel(Level.ERROR)\n",
    "\n",
    "// Create a spark session.\n",
    "val spark = SparkSession.builder().getOrCreate()\n",
    "\n",
    "// Read in the advertising.csv file.\n",
    "val data = spark.read\n",
    "    .option(\"header\",\"true\")\n",
    "    .option(\"inferSchema\",\"true\")\n",
    "    .format(\"csv\").load(\"advertising.csv\")\n",
    "\n",
    "// Print the schema of the dataframe.\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Example Data Row\n",
      "Age\n",
      "35\n",
      "\n",
      "\n",
      "Area Income\n",
      "61833.9\n",
      "\n",
      "\n",
      "Daily Internet Usage\n",
      "256.09\n",
      "\n",
      "\n",
      "Ad Topic Line\n",
      "Cloned 5thgeneration orchestration\n",
      "\n",
      "\n",
      "City\n",
      "Wrightburgh\n",
      "\n",
      "\n",
      "Male\n",
      "0\n",
      "\n",
      "\n",
      "Country\n",
      "Tunisia\n",
      "\n",
      "\n",
      "Timestamp\n",
      "2016-03-27 00:53:11\n",
      "\n",
      "\n",
      "Clicked on Ad\n",
      "0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "colnames: Array[String] = Array(Daily Time Spent on Site, Age, Area Income, Daily Internet Usage, Ad Topic Line, City, Male, Country, Timestamp, Clicked on Ad)\n",
       "firstrow: org.apache.spark.sql.Row = [68.95,35,61833.9,256.09,Cloned 5thgeneration orchestration,Wrightburgh,0,Tunisia,2016-03-27 00:53:11,0]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 2 DISPLAY THE DATA\n",
    "// Print out a sample row of the data (multiple ways to do this)\n",
    "val colnames = data.columns\n",
    "val firstrow = data.head(1)(0)\n",
    "println(\"\\n\")\n",
    "println(\"Example Data Row\")\n",
    "for(ind <- Range(1,colnames.length)){\n",
    "    println(colnames(ind))\n",
    "    println(firstrow(ind))\n",
    "    println(\"\\n\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timedata: org.apache.spark.sql.DataFrame = [Daily Time Spent on Site: double, Age: int ... 9 more fields]\n",
       "logregdataall: org.apache.spark.sql.DataFrame = [label: int, Daily Time Spent on Site: double ... 5 more fields]\n",
       "logregdata: org.apache.spark.sql.DataFrame = [label: int, Daily Time Spent on Site: double ... 5 more fields]\n",
       "assembler: org.apache.spark.ml.feature.VectorAssembler = VectorAssembler: uid=vecAssembler_51fa94905a18, handleInvalid=error, numInputCols=6\n",
       "training: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: int, Daily Time Spent on Site: double ... 5 more fields]\n",
       "test: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: int, Daily Time Spent on Site: double ... 5 more fields]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 2 SETUP DATAFRAME FOR MACHINE LEARNING\n",
    "\n",
    "//    - Rename the Clicked on Ad column to \"label\"\n",
    "//    - Grab the following columns \"Daily Time Spent on Site\",\"Age\",\"Area Income\",\"Daily Internet Usage\",\"Timestamp\",\"Male\"\n",
    "//    - Create a new column called Hour from the Timestamp containing the Hour of the click\n",
    "\n",
    "val timedata = data.withColumn(\"Hour\",hour(data(\"Timestamp\")))\n",
    "\n",
    "val logregdataall = timedata.select(\n",
    "    data(\"Clicked on Ad\").as(\"label\"),\n",
    "    $\"Daily Time Spent on Site\",\n",
    "    $\"Age\",\n",
    "    $\"Area Income\",\n",
    "    $\"Daily Internet Usage\",\n",
    "//     $\"Timestamp\",\n",
    "    $\"Hour\",\n",
    "    $\"Male\")\n",
    "\n",
    "val logregdata = logregdataall.na.drop()\n",
    "\n",
    "// Create a new VectorAssembler object called assembler for the feature\n",
    "// columns as the input Set the output column to be called features\n",
    "\n",
    "val assembler = (new VectorAssembler()\n",
    "    .setInputCols(Array(\n",
    "        \"Daily Time Spent on Site\",\n",
    "        \"Age\",\n",
    "        \"Area Income\",\n",
    "        \"Daily Internet Usage\",\n",
    "//         \"Timestamp\",\n",
    "        \"Hour\",\n",
    "        \"Male\",\n",
    "        ))\n",
    "    .setOutputCol(\"features\"))\n",
    "\n",
    "\n",
    "// Use randomSplit to create a train test split of 70/30\n",
    "val Array(training, test) = logregdata\n",
    "    .randomSplit(Array(0.7, 0.3), seed = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lr: org.apache.spark.ml.classification.LogisticRegression = logreg_1f32e2f9eaa7\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_cbd5233be56d\n",
       "model: org.apache.spark.ml.PipelineModel = pipeline_cbd5233be56d\n",
       "results: org.apache.spark.sql.DataFrame = [label: int, Daily Time Spent on Site: double ... 9 more fields]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 3 SETUP THE PIPE LINE\n",
    "\n",
    "// Create a new LogisticRegression object called lr\n",
    "val lr = new LogisticRegression()\n",
    "\n",
    "// Create a new pipeline with the stages: assembler, lr\n",
    "val pipeline = new Pipeline()\n",
    "    .setStages(Array(assembler, lr))\n",
    "\n",
    "// Fit the pipeline to training set.\n",
    "val model = pipeline.fit(training)\n",
    "\n",
    "// Get Results on Test Set with transform\n",
    "val results = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "136.0  1.0    \n",
      "4.0    146.0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predictionAndLabels: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[94] at rdd at <console>:38\n",
       "metrics: org.apache.spark.mllib.evaluation.MulticlassMetrics = org.apache.spark.mllib.evaluation.MulticlassMetrics@7b285208\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 4 MODEL EVALUATION\n",
    "\n",
    "// Convert the test results to an RDD using .as and .rdd\n",
    "val predictionAndLabels = results.select($\"prediction\",$\"label\").as[(Double, Double)].rdd\n",
    "\n",
    "// Instantiate a new MulticlassMetrics object\n",
    "val metrics = new MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "// Print out the Confusion matrix\n",
    "println(\"Confusion matrix:\")\n",
    "println(metrics.confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "miscellanea_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
